{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use scikit-learn to grid search the number of neurons\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from keras.constraints import maxnorm\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "import matplotlib.path as path\n",
    "import matplotlib.animation as animation\n",
    "\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "from sklearn import svm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import CYP data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cyp2c19_df = pd.read_pickle(\"data/cyp2c19.pkl\")\n",
    "cyp2c9_df = pd.read_pickle(\"data/cyp2c9.pkl\")\n",
    "cyp1a2_df = pd.read_pickle(\"data/cyp1a2.pkl\")\n",
    "cyp2d6_df = pd.read_pickle(\"data/cyp2d6.pkl\")\n",
    "cyp3a4_df = pd.read_pickle(\"data/cyp3a4.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cyp2c19_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train, test, valid set split\n",
    "def split_var(data_set):   \n",
    "    X_data = np.array(data_set)\n",
    "    y_data = np.array(data_set['Inhibition Observed'])\n",
    "    X_train, X_test, y_train, y_test = model_selection.train_test_split(X_data, y_data, test_size = 0.1)\n",
    "    X_train, X_valid, y_train, y_valid = model_selection.train_test_split(X_train, y_train, test_size = 0.11)\n",
    "    return X_train, X_test, X_valid, y_train, y_test, y_valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = cyp2c9_df.drop(cyp2c9_df[['index', 'Inhibition Observed']], axis=1)\n",
    "y = cyp2c9_df['Inhibition Observed']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gridsearch Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "   \n",
    "def svc_tune(swiss_feat):\n",
    "    \n",
    "    X = swiss_feat.drop(columns=['index', 'Inhibition Observed'], axis=1)\n",
    "    y = swiss_feat['Inhibition Observed']\n",
    "    \n",
    "        # Split the dataset in two equal parts\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.5, random_state=0)\n",
    "    \n",
    "    print(__doc__)\n",
    "\n",
    "    # Loading the Digits dataset\n",
    "\n",
    "    # To apply an classifier on this data, we need to flatten the image, to\n",
    "    # turn the data in a (samples, feature) matrix:\n",
    "    n_samples = len(X_train)\n",
    "\n",
    "\n",
    "    # Set the parameters by cross-validation\n",
    "    tuned_parameters = [{'kernel': ['rbf'], 'gamma': [1e-3, 1e-4],\n",
    "                         'C': [1, 10, 100, 1000]},\n",
    "                        {'kernel': ['linear'], 'C': [1, 10, 100, 1000]}]\n",
    "\n",
    "    scores = ['precision', 'recall']\n",
    "\n",
    "    for score in scores:\n",
    "        print(\"# Tuning hyper-parameters for %s\" % score)\n",
    "        print()\n",
    "\n",
    "        clf = GridSearchCV(\n",
    "            SVC(), tuned_parameters, scoring='%s_macro' % score,\n",
    "            n_jobs=-1\n",
    "        )\n",
    "        clf.fit(X_train, y_train)\n",
    "\n",
    "        print(\"Best parameters set found on development set:\")\n",
    "        print()\n",
    "        print(clf.best_params_)\n",
    "        print()\n",
    "        print(\"Grid scores on development set:\")\n",
    "        print()\n",
    "        means = clf.cv_results_['mean_test_score']\n",
    "        stds = clf.cv_results_['std_test_score']\n",
    "        for mean, std, params in zip(means, stds, clf.cv_results_['params']):\n",
    "            print(\"%0.3f (+/-%0.03f) for %r\"\n",
    "                  % (mean, std * 2, params))\n",
    "        print()\n",
    "\n",
    "        print(\"Detailed classification report:\")\n",
    "        print()\n",
    "        print(\"The model is trained on the full development set.\")\n",
    "        print(\"The scores are computed on the full evaluation set.\")\n",
    "        print()\n",
    "        y_true, y_pred = y_test, clf.predict(X_test)\n",
    "        print(classification_report(y_true, y_pred))\n",
    "        print()\n",
    "    return classification_report(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CYP2c19 Fingerprint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature df merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_df_merged = pd.read_pickle('data/feature_df_merged.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svc_tune(feature_df_merged)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = swiss_feat_df.drop(columns=[['index', 'Inhibition Observed']], axis=1)\n",
    "y = swiss_feat_df['Inhibition Observed']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_svm = Pipeline([\n",
    "    ('bow', CountVectorizer()),\n",
    "    ('tfidf', TfidfTransformer()),\n",
    "    ('classifier', SVC(probability=True)),])\n",
    "\n",
    "# pipeline parameters to automatically explore and tune\n",
    "param_svm = [\n",
    "  {'classifier__C': [1, 10, 100, 1000], 'classifier__kernel': ['linear']},\n",
    "  {'classifier__C': [1, 10, 100, 1000], 'classifier__gamma': [0.001, 0.0001], 'classifier__kernel': ['rbf']},\n",
    "]\n",
    "\n",
    "grid_svm = GridSearchCV(\n",
    "    pipeline_svm,\n",
    "    param_grid=param_svm,\n",
    "    refit=True,\n",
    "    n_jobs=-1, \n",
    "    scoring='accuracy',\n",
    "    cv=StratifiedKFold(label_train, n_folds=5),)\n",
    "\n",
    "svm_detector_reloaded = cPickle.load(open('svm_sentiment_analyzer.pkl', 'rb'))\n",
    "print(svm_detector_reloaded.predict([\"\"\"\"Today is awesome day\"\"\"])[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "pickle.dump(grid_svm, open('svm_sentiment_analyzer.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_detector_reloaded = pickle.load(open('svm_sentiment_analyzer.pkl', 'rb'))\n",
    "print(svm_detector_reloaded.predict_proba([\"Today is an awesome day\"])[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_svm.fit(sents.Sentence.values, sents.Positive.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_calib, y_train, y_calib = train_test_split(\n",
    "       X, y, random_state=42\n",
    ")\n",
    "\n",
    "\n",
    "plt.figure(figsize=(10, 10))\n",
    "colors = [\"r\", \"g\", \"b\"]\n",
    "\n",
    "clf_probs = clf.predict_proba(X_test)\n",
    "cal_clf_probs = cal_clf.predict_proba(X_test)\n",
    "# Plot arrows\n",
    "for i in range(clf_probs.shape[0]):\n",
    "    plt.arrow(clf_probs[i, 0], clf_probs[i, 1],\n",
    "              cal_clf_probs[i, 0] - clf_probs[i, 0],\n",
    "              cal_clf_probs[i, 1] - clf_probs[i, 1],\n",
    "              color=colors[y_test[i]], head_width=1e-2)\n",
    "\n",
    "# Plot perfect predictions, at each vertex\n",
    "plt.plot([1.0], [0.0], 'ro', ms=20, label=\"Class 1\")\n",
    "plt.plot([0.0], [1.0], 'go', ms=20, label=\"Class 2\")\n",
    "plt.plot([0.0], [0.0], 'bo', ms=20, label=\"Class 3\")\n",
    "\n",
    "# Plot boundaries of unit simplex\n",
    "plt.plot([0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0], 'k', label=\"Simplex\")\n",
    "\n",
    "# Annotate points 6 points around the simplex, and mid point inside simplex\n",
    "plt.annotate(r'($\\frac{1}{3}$, $\\frac{1}{3}$, $\\frac{1}{3}$)',\n",
    "             xy=(1.0/3, 1.0/3), xytext=(1.0/3, .23), xycoords='data',\n",
    "             arrowprops=dict(facecolor='black', shrink=0.05),\n",
    "             horizontalalignment='center', verticalalignment='center')\n",
    "plt.plot([1.0/3], [1.0/3], 'ko', ms=5)\n",
    "plt.annotate(r'($\\frac{1}{2}$, $0$, $\\frac{1}{2}$)',\n",
    "             xy=(.5, .0), xytext=(.5, .1), xycoords='data',\n",
    "             arrowprops=dict(facecolor='black', shrink=0.05),\n",
    "             horizontalalignment='center', verticalalignment='center')\n",
    "plt.annotate(r'($0$, $\\frac{1}{2}$, $\\frac{1}{2}$)',\n",
    "             xy=(.0, .5), xytext=(.1, .5), xycoords='data',\n",
    "             arrowprops=dict(facecolor='black', shrink=0.05),\n",
    "             horizontalalignment='center', verticalalignment='center')\n",
    "plt.annotate(r'($\\frac{1}{2}$, $\\frac{1}{2}$, $0$)',\n",
    "             xy=(.5, .5), xytext=(.6, .6), xycoords='data',\n",
    "             arrowprops=dict(facecolor='black', shrink=0.05),\n",
    "             horizontalalignment='center', verticalalignment='center')\n",
    "plt.annotate(r'($0$, $0$, $1$)',\n",
    "             xy=(0, 0), xytext=(.1, .1), xycoords='data',\n",
    "             arrowprops=dict(facecolor='black', shrink=0.05),\n",
    "             horizontalalignment='center', verticalalignment='center')\n",
    "plt.annotate(r'($1$, $0$, $0$)',\n",
    "             xy=(1, 0), xytext=(1, .1), xycoords='data',\n",
    "             arrowprops=dict(facecolor='black', shrink=0.05),\n",
    "             horizontalalignment='center', verticalalignment='center')\n",
    "plt.annotate(r'($0$, $1$, $0$)',\n",
    "             xy=(0, 1), xytext=(.1, 1), xycoords='data',\n",
    "             arrowprops=dict(facecolor='black', shrink=0.05),\n",
    "             horizontalalignment='center', verticalalignment='center')\n",
    "# Add grid\n",
    "plt.grid(False)\n",
    "for x in [0.0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0]:\n",
    "    plt.plot([0, x], [x, 0], 'k', alpha=0.2)\n",
    "    plt.plot([0, 0 + (1-x)/2], [x, x + (1-x)/2], 'k', alpha=0.2)\n",
    "    plt.plot([x, x + (1-x)/2], [0, 0 + (1-x)/2], 'k', alpha=0.2)\n",
    "\n",
    "plt.title(\"Change of predicted probabilities on test samples \"\n",
    "          \"after sigmoid calibration\")\n",
    "plt.xlabel(\"Probability class 1\")\n",
    "plt.ylabel(\"Probability class 2\")\n",
    "plt.xlim(-0.05, 1.05)\n",
    "plt.ylim(-0.05, 1.05)\n",
    "_ = plt.legend(loc=\"best\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import log_loss\n",
    "\n",
    "score = log_loss(y_test, clf_probs)\n",
    "cal_score = log_loss(y_test, cal_clf_probs)\n",
    "\n",
    "print(\"Log-loss of\")\n",
    "print(f\" * uncalibrated classifier: {score:.3f}\")\n",
    "print(f\" * calibrated classifier: {cal_score:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 10))\n",
    "# Generate grid of probability values\n",
    "p1d = np.linspace(0, 1, 20)\n",
    "p0, p1 = np.meshgrid(p1d, p1d)\n",
    "p2 = 1 - p0 - p1\n",
    "p = np.c_[p0.ravel(), p1.ravel(), p2.ravel()]\n",
    "p = p[p[:, 2] >= 0]\n",
    "\n",
    "# Use the three class-wise calibrators to compute calibrated probabilities\n",
    "calibrated_classifier = cal_clf.calibrated_classifiers_[0]\n",
    "prediction = np.vstack([calibrator.predict(this_p)\n",
    "                        for calibrator, this_p in\n",
    "                        zip(calibrated_classifier.calibrators, p.T)]).T\n",
    "\n",
    "# Re-normalize the calibrated predictions to make sure they stay inside the\n",
    "# simplex. This same renormalization step is performed internally by the\n",
    "# predict method of CalibratedClassifierCV on multiclass problems.\n",
    "prediction /= prediction.sum(axis=1)[:, None]\n",
    "\n",
    "# Plot changes in predicted probabilities induced by the calibrators\n",
    "for i in range(prediction.shape[0]):\n",
    "    plt.arrow(p[i, 0], p[i, 1],\n",
    "              prediction[i, 0] - p[i, 0], prediction[i, 1] - p[i, 1],\n",
    "              head_width=1e-2, color=colors[np.argmax(p[i])])\n",
    "\n",
    "# Plot the boundaries of the unit simplex\n",
    "plt.plot([0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0], 'k', label=\"Simplex\")\n",
    "\n",
    "plt.grid(False)\n",
    "for x in [0.0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0]:\n",
    "    plt.plot([0, x], [x, 0], 'k', alpha=0.2)\n",
    "    plt.plot([0, 0 + (1-x)/2], [x, x + (1-x)/2], 'k', alpha=0.2)\n",
    "    plt.plot([x, x + (1-x)/2], [0, 0 + (1-x)/2], 'k', alpha=0.2)\n",
    "\n",
    "plt.title(\"Learned sigmoid calibration map\")\n",
    "plt.xlabel(\"Probability class 1\")\n",
    "plt.ylabel(\"Probability class 2\")\n",
    "plt.xlim(-0.05, 1.05)\n",
    "plt.ylim(-0.05, 1.05)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_clf = GaussianNB()\n",
    "calibrated_clf = CalibratedClassifierCV(base_estimator=base_clf, cv=3)\n",
    "calibrated_clf.fit(X, y)\n",
    "\n",
    "len(calibrated_clf.calibrated_classifiers_)\n",
    "\n",
    "calibrated_clf.predict_proba(X)[:5, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X\n",
    "y = y\n",
    "regr = svm.SVR()\n",
    "regr.fit(X, y)\n",
    "\n",
    "regr.predict([[1, 1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fixing random state for reproducibility\n",
    "np.random.seed(19680801)\n",
    "\n",
    "# histogram our data with numpy\n",
    "data = cyp3a4_swiss_feat\n",
    "n, bins = np.histogram(data, 100)\n",
    "\n",
    "# get the corners of the rectangles for the histogram\n",
    "left = bins[:-1]\n",
    "right = bins[1:]\n",
    "bottom = np.zeros(len(left))\n",
    "top = bottom + n\n",
    "nrects = len(left)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nverts = nrects * (1 + 3 + 1)\n",
    "verts = np.zeros((nverts, 2))\n",
    "codes = np.full(nverts, path.Path.LINETO)\n",
    "codes[0::5] = path.Path.MOVETO\n",
    "codes[4::5] = path.Path.CLOSEPOLY\n",
    "verts[0::5, 0] = left\n",
    "verts[0::5, 1] = bottom\n",
    "verts[1::5, 0] = left\n",
    "verts[1::5, 1] = top\n",
    "verts[2::5, 0] = right\n",
    "verts[2::5, 1] = top\n",
    "verts[3::5, 0] = right\n",
    "verts[3::5, 1] = bottom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "patch = None\n",
    "\n",
    "\n",
    "def animate(i):\n",
    "    # simulate new data coming in\n",
    "    data = cyp3a4_swiss_feat\n",
    "    n, bins = np.histogram(data, 100)\n",
    "    top = bottom + n\n",
    "    verts[1::5, 1] = top\n",
    "    verts[2::5, 1] = top\n",
    "    return [patch, ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "patch = None\n",
    "\n",
    "\n",
    "def animate(i):\n",
    "    # simulate new data coming in\n",
    "    data = cyp3a4_swiss_feat\n",
    "    n, bins = np.histogram(data, 100)\n",
    "    top = bottom + n\n",
    "    verts[1::5, 1] = top\n",
    "    verts[2::5, 1] = top\n",
    "    return [patch, ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
